ConcurrentHashMap的锁分段技术

ConcurrentHashMap的读是否要加锁，为什么

ConcurrentHashMap的迭代器是强一致性的迭代器还是弱一致性的迭代器

你的项目中用到了哪些设计模式，如何使用

知道常用设计模式的优缺点

能画出常用设计模式的UML图

synchronized和ReentrantLock的区别

wait、notify和notifyAll
	JVM会为一个使用内部锁（synchronized）的对象维护两个集合，Entry Set和Wait Set，也有人翻译为锁池和等待池
	Entry Set
		如果线程A已经持有了对象锁，此时如果有其他线程也想获得该对象锁的话，它只能进入Entry Set，并且处于线程的BLOCKED状态。
		Entry Set中的线程，当对象锁被释放的时候，JVM会唤醒处于Entry Set中的某一个线程，这个线程的状态就从BLOCKED转变为RUNNABLE
	Wait Set
		如果线程A调用了wait()方法，那么线程A会释放该对象的锁，进入到Wait Set，并且处于线程的WAITING状态。
		Wait Set中的线程，当对象的notify()方法被调用时，JVM会唤醒处于Wait Set中的某一个线程，这个线程的状态就从WAITING转变为RUNNABLE
		或者当notifyAll()方法被调用时，Wait Set中的全部线程会转变为RUNNABLE状态。所有Wait Set中被唤醒的线程会被转移到Entry Set

	还有需要注意的是，某个线程B想要获得对象锁，一般情况下有两个先决条件，一是对象锁已经被释放了
	（如曾经持有锁的前任线程A执行完了synchronized代码块或者调用了wait()方法等等），二是线程B已处于RUNNABLE状态


synchronized锁普通方法和锁静态方法

死锁的原理及排查方法等等。
	jstack 导出线程堆栈查看 其 monitor对象 与 held的锁;

List、Map、Set实现类的源代码

ReentrantLock、AQS的源代码

AtomicInteger的实现原理，主要能说清楚CAS机制并且AtomicInteger是如何利用CAS机制实现的
	乐观锁用到的主要机制就是CAS。Compare And Swap。
	CAS有三个操作数，内存数据v，旧的预期数据A，要修改的数据B。每次进行数据更新时，当且仅当预期值A和内存中的数据V相同时，
	才将内存中的数据修改为B，否则什么也不做。
	不影响和挂起其他线程实现原子性操作，能大大提升运行时的性能，但是会导致一个ABA的问题。

线程池的实现原理
	其实java线程池的实现原理很简单，说白了就是一个线程集合workerSet和一个阻塞队列workQueue。
	当用户向线程池提交一个任务(也就是线程)时，线程池会先将任务放入workQueue中。
	workerSet中的线程会不断的从workQueue中获取线程然后执行。当workQueue中没有任务的时候，worker就会阻塞，直到队列中有任务了就取出来继续执行

	任务提交后的流程分析
		用户通过submit提交一个任务。线程池会执行如下流程:
		1. 判断当前运行的worker数量是否超过corePoolSize,如果不超过corePoolSize。就创建一个worker直接执行该任务。—— 线程池最开始是没有worker在运行的
		2. 如果正在运行的worker数量超过或者等于corePoolSize,那么就将该任务加入到workQueue队列中去。
		3. 如果workQueue队列满了,也就是offer方法返回false的话，就检查当前运行的worker数量是否小于maximumPoolSize,如果小于就创建一个worker直接执行该任务。
		4. 如果当前运行的worker数量是否大于等于maximumPoolSize，那么就执行RejectedExecutionHandler来拒绝这个任务的提交。

	Worker的结构
		Worker是ThreadPoolExecutor内部定义的一个内部类
		private final class Worker extends AbstractQueuedSynchronizer implements Runnable
		它实现了Runnable接口,所以可以拿来当线程用。同时它还继承了AbstractQueuedSynchronizer同步器类,主要用来实现一个不可重入的锁。


Object类中的方法以及每个方法的作用
	wait()
	notify()
	notifyAll()唤醒在此对象监视器上等待的所有线程
		永远都要把wait()放到循环语句里面。
		notify方法很容易引起死锁，除非你根据自己的程序设计，确定不会发生死锁，notifyAll方法则是线程的安全唤醒方法
		void notify(): 唤醒一个正在等待该对象的线程。
			notify他只是选择一个wait状态线程进行通知，并使它获得该对象上的锁，但不惊动其他同样在等待被该对象notify的线程们
		void notifyAll(): 唤醒所有正在等待该对象的线程。

	finalize() throws Throwable当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法。子类重写 finalize 方法，以配置系统资源或执行其他清除

	线程通信：
		Object类的wait()、notify() 、notifyAll()三个方法必须由同步监视器对象来调用，分两种情况：
			a)同步方法，该类默认实例（this）就是同步监视器，可以在同步方法中可以直接调用
			b)同步代码块，同步监视器是synchronized后括号里的对象，所以必须使用此对象调用这三个方法

		condition对象通过lock.newCondition()来创建，用condition.await（）来实现让线程等待，是线程进入阻塞。
		用condition.signal()来实现唤醒线程。唤醒的线程是用同一个conditon对象调用await()方法而进入阻塞。
		并且和wait/notify一样，await（）和signal（）也是在同步代码区内执行。



Java虚拟机的内存布局 --- 1.8
	1.线程私有区域
		程序计数器
		本地方法栈
		虚拟机栈
			每个方法执行的时候都会创建一个栈帧（stack frame）用于存放 局部变量表、操作栈、动态链接、方法出口。
				八大基本类型，对象引用，返回地址
			方法先进后出  -Xss 线程栈深度 不足报错：StackOverflowError

	2.线程共有区域
		堆内存
			所有的对象实例及数组都在对上进行分配
			young   1/3
				eden  8/10
					JAVA对象优先在Eden区分配，当Eden区没有足够的空间时触发一次Minor GC ，触发Minor GC时，
					Eden和from区中的存活对象会被复制到to区，然后from和to交换指针，以保证下次Minor GC时，to区还是空的，
					如果survival区无法容纳的对象将通过分配担保机制直接进入老年区
				from  1/10

				to    1/10
				-Xmn1024m 设置yong区大小
			old     2/3
			设置参数： -Xms 500m  -Xmx 500m

		元数据(直接使用本地内存 -- 1.8 特性)
			放虚拟机加载的类信息，静态变量，常量等数据。
			设置参数： -XX:MetaspaceSize=8m -XX:MaxMetaspaceSize=50m

		直接内存
			jdk1.4引入了NIO，它可以使用Native函数库直接分配堆外内存


	3.JVM的常量池
		类文件中常量池
			位置： 堆
			class常量池是在编译的时候每个class都有的，在编译阶段，存放的是常量的符号引用。
			常量池中存放的是符号信息，java虚拟机在执行指令的时候会依赖这些信息
		运行时常量池
			位置：元空间
			诞生时间：JVM运行时
			内容概要：class文件元信息描述，编译后的代码数据，引用类型数据，类文件常量池。
			所谓的运行时常量池其实就是将编译后的类信息放入运行时的一个区域中，用来动态获取类信息。
			运行时常量池是在类加载完成之后，将每个class常量池中的符号引用值转存到运行时常量池中，
			也就是说，每个class都有一个运行时常量池，类在解析之后，将符号引用替换成直接引用，与全局常量池中的引用值保持一致
		String常量池
			位置：堆

JVM Server模式与client模式
	-Server模式启动时，速度较慢，但是一旦运行起来后，性能将会有很大的提升
	-client模式的时候,使用的是一个代号为C1的轻量级编译器,
	而-server模式启动的虚拟机采用相对重量级,代号为C2的编译器. C2比C1编译器编译的相对彻底,,服务起来之后,性能更高

类加载机制，也就是双亲委派模型


happens-before规则

volatile关键字使用规则
	volatile关键字修饰的变量看到的随时是自己的最新值;保证读取是在上一次操作完后之后


谈谈分布式Session的几种实现方式

讲一下Session和Cookie的区别和联系以及Session的实现原理
----------------------------------------------------------------------------------------------
1.hashMap实现原理，concurrentHashMap实现原理
	jdk 8 之前，其内部是由数组+链表来实现的，而 jdk 8 对于链表长度超过 8 的链表将转储为红黑树
	HashMap的基本存储原理以及存储内容的组成
	hashMap：
		基本原理：先声明一个下标范围比较大的数组来存储元素。另外设计一个哈希函数（也叫做散列函数）来获得每一个元素的Key（关键字）的函数值（即数组下标，hash值）相对应，数组存储的元素是一个Entry类，这个类有三个数据域，key、value（键值对），next(指向下一个Entry)。
		例如， 第一个键值对A进来。通过计算其key的hash得到的index=0。记做:Entry[0] = A。
		第二个键值对B，通过计算其index也等于0， HashMap会将B.next =A,Entry[0] =B,
		第三个键值对 C,index也等于0,那么C.next = B,Entry[0] = C；这样我们发现index=0的地方事实上存取了A,B,C三个键值对,它们通过next这个属性链接在一起。我们可以将这个地方称为桶。 对于不同的元素，可能计算出了相同的函数值，这样就产生了“冲突”，这就需要解决冲突，“直接定址”与“解决冲突”是哈希表的两大特点。

		HashMap的工作原理以及存取方法过程

		HashMap的工作原理 ：HashMap是基于散列法（又称哈希法hashing）的原理，使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法，返回的hashCode用于找到bucket（桶）位置来储存Entry对象。”HashMap是在bucket中储存键对象和值对象，作为Map.Entry。并不是仅仅只在bucket中存储值。

		HashMap具体的存取过程如下：
		put键值对的方法的过程是：
		这里写图片描述
		①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容；
		②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③；
		③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals；
		④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤；
		⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；
		⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。

		get值方法的过程是:
			1、指定key 通过hash函数得到key的hash值
			int hash=key.hashCode();
			2、调用内部方法 getNode()，得到桶号(一般都为hash值对桶数求模)
				int index =hash%Entry[].length;
			3、比较桶的内部元素是否与key相等，若都不相等，则没有找到。相等，则取出相等记录的value。
			4、如果得到 key 所在的桶的头结点恰好是红黑树节点，就调用红黑树节点的 getTreeNode() 方法，否则就遍历链表节点。getTreeNode 方法使通过调用树形节点的 find()方法进行查找。由于之前添加时已经保证这个树是有序的，因此查找时基本就是折半查找，效率很高。
			5、如果对比节点的哈希值和要查找的哈希值相等，就会判断 key 是否相等，相等就直接返回；不相等就从子树中递归查找。
			HashMap中直接地址用hash函数生成；解决冲突，用比较函数解决。如果每个桶内部只有一个元素，那么查找的时候只有一次比较。当许多桶内没有值时，许多查询就会更快了(指查不到的时候)。
			HashMap中的碰撞探测(collision detection)以及碰撞的解决方法
			当两个对象的hashcode相同时，它们的bucket位置相同，‘碰撞’会发生。因为HashMap使用LinkedList存储对象，这个Entry(包含有键值对的Map.Entry对象)会存储在LinkedList中。这两个对象就算hashcode相同，但是它们可能并不相等。 那如何获取这两个对象的值呢？当我们调用get()方法，HashMap会使用键对象的hashcode找到bucket位置，遍历LinkedList直到找到值对象。找到bucket位置之后，会调用keys.equals()方法去找到LinkedList中正确的节点，
			最终找到要找的值对象使用不可变的、声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。

		如何重新调整HashMap的大小

		“如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？”
		默认的负载因子大小为0.75，也就是说，当一个map填满了75%的bucket时候，和其它集合类(如ArrayList等)一样，将会创建原来HashMap大小的两倍的bucket数组，来重新调整map的大小，并将原来的对象放入新的bucket数组中。这个过程叫作rehashing，因为它调用hash方法找到新的bucket位置。

	concurrentHashMap：1.7和1.8实现不一样   1.8：synchronized+CAS+HashEntry+红黑树
		put操作：
			如果没有初始化就先调用initTable（）方法来进行初始化过程
			如果没有hash冲突就直接CAS插入
			如果还在进行扩容操作就先进行扩容
			如果存在hash冲突，就加锁来保证线程安全，这里有两种情况，一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入，
			最后一个如果该链表的数量大于阈值8，就要先转换成黑红树的结构，break再一次进入循环
			如果添加成功就调用addCount（）方法统计size，并且检查是否需要扩容

		get操作：
			计算hash值，定位到该table索引位置，如果是首节点符合就返回
			如果遇到扩容的时候，会调用标志正在扩容节点ForwardingNode的find方法，查找该节点，匹配就返回
			以上都不符合的话，就往下遍历节点，匹配就返回，否则最后就返回null

2.TCP,UDP区别，为什么可靠和不可靠
	1、TCP与UDP区别总结：
		1）TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接
		2）TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付
			Tcp通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制。
		3）UDP具有较好的实时性，工作效率比TCP高，适用于对高速传输和实时性有较高的通信或广播通信。
		4）每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信
		5）TCP对系统资源要求较多，UDP对系统资源要求较少

	2、为什么UDP有时比TCP更有优势?
		UDP以其简单、传输快的优势，在越来越多场景下取代了TCP,如实时游戏。
		（1）网速的提升给UDP的稳定性提供可靠网络保障，丢包率很低，如果使用应用层重传，能够确保传输的可靠性。
		（2）TCP为了实现网络通信的可靠性，使用了复杂的拥塞控制算法，建立了繁琐的握手过程，由于TCP内置的系统协议栈中，极难对其进行改进。
			采用TCP，一旦发生丢包，TCP会将后续的包缓存起来，等前面的包重传并接收到后再继续发送，延时会越来越大，基于UDP对实时性要求较为严格的情况下，采用自定义重传机制，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成影响。

3.一次HTTP请求的全过程，包括域名解析。定位主机
	HTTP请求：
		请求行、请求头、内容实体组成的
	HTTP响应：
		状态行、响应首部字段（响应头）、响应实体组成

4.TCP三次握手


5.Mysql事物是什么？四大特性，四大隔离级别
　　 1、原子性（Atomicity）：事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。
　　 2、一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到。
　　 3、隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。
　　 4、持久性（Durability）：事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。


6.ConcurrentHashMap和Hashtable区别
7.springIOC和AOP,以及各有什么优点
	IOC：
		1）内存控制：统一管理对象，避免对象乱创建导致额外的内存开销。便于内存的优化。
		2）降低耦合度：便于项目的扩展、易于维护。如果IoC+接口情况下，删除任意实现类都不会导致程序编译出错。
			虽然运行到特定得代码会报错，但是其他代码在使用时不会有问题
		3）spring的DI机制降低了业务对象替换的复杂性
		4）容器提供单例模式支持
	AOP：
		我们需要为分散的对象引入公共行为的时候，OOP就显得无力，OOP不能解决从左到右的关系，例如日志，权限，事务之类的代码往往分散于很多代码中，在OOP设计中，这导致了大量代码的重复，
		我们可以把这些代码封装成一个切面，然后注入到目标对象中


8.有哪几种常用的线程池
	线程池作用：
		1）创建/销毁线程伴随着系统开销，过于频繁的创建/销毁线程，会很大程度上影响处理效率
		2）线程并发数量过多，抢占系统资源从而导致阻塞
		3）对线程进行一些简单的管理
	java中的有哪些线程池？
		1.newCachedThreadPool创建一个可缓存线程池程
			newCachedThreadPool,是一种线程数量不定的线程池，并且其最大线程数为Integer.MAX_VALUE，
			这个数是很大的，一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，
			则新建线程。但是线程池中的空闲线程都有超时限制，这个超时时长是60秒，超过60秒闲置线程就会被回收。
			调用execute将重用以前构造的线程(如果线程可用)。这类线程池比较适合执行大量的耗时较少的任务，
			当整个线程池都处于闲置状态时，线程池中的线程都会超时被停止。
		2.newFixedThreadPool 创建一个定长线程池
			创建一个指定工作线程数量的线程池，每当提交一个任务就创建一个工作线程，当线程 处于空闲状态时，
			它们并不会被回收，除非线程池被关闭了，如果工作线程数量达到线程池初始的最大数，
			则将提交的任务存入到池队列（没有大小限制）中。由于newFixedThreadPool只有核心线程并且这些核心线程不会被回收，
			这样它更加快速底相应外界的请求。
		3.newScheduledThreadPool 创建一个定长线程池
			创建一个线程池，它的核心线程数量是固定的，而非核心线程数是没有限制的，并且当非核心线程闲置时会被立即回收，
			它可安排给定延迟后运行命令或者定期地执行。这类线程池主要用于执行定时任务和具有固定周期的重复任务。
		4.newSingleThreadExecutor 创建一个单线程化的线程池
			这类线程池内部只有一个核心线程，以无界队列方式来执行该线程，这使得这些任务之间不需要处理线程同步的问题，它确保所有的任务都在同一个线程中按顺序中执行，
			并且可以在任意给定的时间不会有多个线程是活动的。

9.什么情况使用Runable和Thread创建线程，Runable和Callable区别
	(1)Callable规定的方法是call()，Runnable规定的方法是run()。其中Runnable可以提交给Thread来包装下，直接启动一个线程来执行，
		而Callable则一般都是提交给ExecuteService或Future来执行。
	(2)Callable的任务执行后可返回值，而Runnable的任务是不能返回值得
	(3)call方法可以抛出异常，run方法不可以
	(4)运行Callable任务可以拿到一个Future对象，c表示异步计算的结果。

10.线程方法是异常如何处理，副线程可以捕获到么
	1.子线程try...cathch
	2.Future的get方法捕获异常

11.synchronized和锁的区别，什么情况下使用synchronized和ReentrantLock
	两者区别：
		1.首先synchronized是java内置关键字，在jvm层面，Lock是个java类；
		2.synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁；
		3.synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，
			Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；
		4.用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。
			如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；
		5.synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可判断、可公平（两者皆可）
		6.Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。

	1.Synchronized
		Synchronized进过编译，会在同步块的前后分别形成monitorenter和monitorexit这个两个字节码指令。
		在执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加1，
		相应的，在执行monitorexit指令时会将锁计算器就减1，当计算器为0时，锁就被释放了。
		如果获取对象锁失败，那当前线程就要阻塞，直到对象锁被另一个线程释放为止。
	2.ReentrantLock
		ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。
		想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。

		由于ReentrantLock是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能，主要有以下3项：
			1)等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于Synchronized来说可以避免出现死锁的情况。
				通过lock.lockInterruptibly()来实现这个机制。
			2)公平锁，多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，
				ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。


12.JVM的对象分配在哪个区，Class对象分配在哪个区
	Class对象分配在元空间

1.JAVA什么情况出现内存溢出
	内存泄漏定义（memory leak）：一个不再被程序使用的对象或变量还在内存中占有存储空间。
     一次内存泄漏似乎不会有大的影响，但内存泄漏堆积后的后果就是内存溢出。

	内存溢出 out of memory :指程序申请内存时，没有足够的内存供申请者使用

	引起内存溢出的原因有很多种，常见的有以下几种：
         内存中加载的数据量过于庞大，如一次从数据库取出过多数据；
        集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；
         代码中存在死循环或循环产生过多重复的对象实体；
         使用的第三方软件中的BUG；
         启动参数内存值设定的过小；

2.双亲委派模型没为什么这样做
	如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成。
	每一个层次的类加载器都是如此。因此，所有的加载请求最终都应该传送到顶层的启动类加载器中。
	只有当父加载器反馈自己无法完成这个加载请求时（搜索范围中没有找到所需的类），子加载器才会尝试自己去加载。

3.对象什么情况下进入老年代
	1.长期存活的对象将进入老年代
		虚拟机给每个对象定义了对象年龄（Age）计数器。如果对象在Eden出生并经过第一次Minor GC后仍然存活，
		并且能被Survivor容纳的话，将被移动到Survivor空间中，对象年龄设为1。
		对象在Survivor区中每“熬过”一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁），就将会被晋升到老年代中。
	2.对象的内存大于Eden空间（大对象）

4.AOP实现原理

5.BIO,NIO,AIO
	1.BIO
		同步阻塞
		服务器实现模式：一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，
		如果这个连接不做任何事情会造成不必要的线程开销。
	2.NIO
		同步非阻塞
		服务器实现模式为一个请求一个线程，但客户端发送的连接请求都会注册到多路复用器上，
		多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。
	3.AIO

6.消息中间件有哪些，他们之间的优劣势
7.Redis，持久化框架

8.栈和队列
	Stack/ queue

9.垃圾回收算法
	1.判断对象是否可以被回收：
		(1).引用计数算法：（循环应用问题）
			给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；
			任何时刻计数器都为0的对象就是不再被使用的，垃圾收集器将回收该对象使用的内存。
		(2).根搜索算法：
			通过一系列的名为“GC Root”的对象作为起点，从这些节点向下搜索，搜索所走过的路径称为引用链(Reference Chain)，
			当一个对象到GC Root没有任何引用链相连时，则该对象不可达，该对象是不可使用的，垃圾收集器将回收其所占的内存。

			Java语言中，可作为GC Roots的对象包括下面几种：
			??a) 虚拟机栈中引用的对象（栈帧中的本地变量表）；
			??b) 方法区中类静态属性引用的对象；
			??c) 方法区中常量引用的对象；
			??d) 本地方法栈中JNI（Native方法）引用的对象。
		(3).方法区如何判断是否需要回收 (不知道是否适用于 JDK8)
			方法区主要回收的内容有：废弃常量和无用的类。对于废弃常量也可通过引用的可达性来判断，
			但是对于无用的类则需要同时满足下面3个条件：
				该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例；
				加载该类的ClassLoader已经被回收；
				该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法


	2.垃圾回收算法：
		(1)标记-清除（Mark-Sweep）
			算法是最基础的收集算法，算法名字表明这个算法的垃圾收集过程包括两步：
			标记和清除。前面介绍的判定垃圾的过程就是标记过程，在标记过后的清除过程中会清理标记为垃圾的对象。
			后序的垃圾收集算法都是在这个算法的基础上改进而成的。这个算法有两个不足：一个就是标记和清除的效率不高；
			第二个是空间问题，标记清除后会产生大量不连续的内存碎片，空间碎片太多的话可能导致以后分配大块内存时失败的问题，这样就会触发另一次垃圾收集操作
		(2)复制算法
			复制算法是为了解决标记-清除算法效率不高的问题的，它将可用内存按照容量分为大小相等的两部分，每次只使用其中的一块。当一块的内存用完了，就将还存活的对象复制到另一块，
			然后再把已经使用过的内存空间一次性清理掉。这样使得每次是对整个半区进行内存回收，内存分配时也不需要考虑内存碎片的问题，
		(3)标记-整理算法
			复制收集算法在对象存活率较高时就需要进行较多的复制操作，效率就会降低
			老年代的特点，可以使用另一种标记-整理（Mark-Compact）算法，标记过程和标记-清除算法一样，
			但后续步骤不是直接对可回收对象进行清理，而是整理存活的对象，将存活的对象都向一端移动，然后直接清理掉边界外的内存

	3.垃圾收集器
		新生代收集器：Serial、ParNew、Parallel Scavenge；
		老年代收集器：Serial Old、Parallel Old、CMS；
		整堆收集器：G1；

		java -XX:+PrintCommandLineFlags -version 命名可以查看当前使用JVM的启动命名包括默认的GC策略


		Parallel Scavenge：
			1、特点
				该垃圾收集器适用于新生代，采用标记复制算法、多线程模型进行垃圾收集
				与其他新生代垃圾收集器的差别是，它更关注于吞吐量，而不是停顿时间
			2、使用场景
				需要与用户交互的程序更关注较短的停顿时间，而如果是需要达成尽量大的吞吐量的话，则该处理器会更加适
			3、设置参数
				-XX：UseAdaptiveSizePolicy

		Serial Old：
			1、特点
				老年代收集，单线程，标记整理算法，暂停所有用户线程
			2、使用场景
				默认的


		Parallel收集器 (JDK8 默认使用发GC策略)
			1、特点
				使用的垃圾收集器是：新生代（Parallel Scavenge），老年代（Ps MarkSweep === Serial Old）组合
				采用多线程来通过扫描并压缩堆
				停顿时间短，回收效率高，对吞吐量要求高。
			2、适用场景
				大型应用，科学计算，大规模数据采集等。
			3、设置参数
				XX:+USeParNewGC 打开并发标记扫描垃圾回收器


		CMS:
		并发标记清理（Concurrent Mark Sweep，CMS）收集器也称为并发低停顿收集器（Concurrent Low Pause Collector）或低延迟（low-latency）垃圾收集器；
			1、特点
				针对老年代；
				基于"标记-清除"算法(不进行压缩操作，产生内存碎片)；
				以获取最短回收停顿时间为目标；
				并发收集、低停顿；
				需要更多的内存（看后面的缺点）；
			2、应用场景
				与用户交互较多的场景；
				希望系统停顿时间最短，注重服务的响应速度；
				以给用户带来较好的体验；
				目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类尤其重视服务的响应速度，希望系统停顿时间最短
			3、设置参数
				"-XX:+UseConcMarkSweepGC"：指定使用CMS收集器；
			4、收集过程
				1.初始标记(CMS initial mark) -stop the world
				2.并发标记(CMS concurrent mark)
				3.重新标记(CMS remark) -stop the world
				4.并发清除(CMS concurrent sweep)
					初始标记，重新标记这两个步骤仍然需要Stop The World, 初始标记仅仅标记以下GC Roots能直接关联的对象，速度很快。
					并发标记就是进行GC Roots Tracing的过程；
					而重新标记阶段则是为了修正并发标记期间因为用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。这个阶段停顿比初始标记稍微长，但远比并发标记的时间短。
					整个过程耗时最长的并发标记和并发清除过程，收集器都可以与用户线程一起工作。总体上来说，CMS收集器的内存回收过程与用户线程一起并发执行的。
					CMS特点：并发收集，低停顿
			5、缺点
				1.CMS收集器对CPU资源非常敏感。默认启动的回收线程数是(CPU+3)/4. 当CPU 4个以上时，并发回收垃圾收集线程不少于25%的CPU资源。
				2.CMS收集器无法处理浮动垃圾(Floating Garbage), 可能出现”Concurrent Mode Failure“失败而导致另一次Full GC的产生。
					由于CMS并发清理时，用户线程还在运行，伴随产生新垃圾，而这一部分出现在标记之后，只能下次GC时再清理。这一部分垃圾就称为”浮动垃圾“。
					由于CMS运行时还需要给用户空间继续运行，则不能等老年代几乎被填满再进行收集，需要预留一部分空间提供并发收集时，用户程序运行。
					JDK1.6中，CMS启动阈值为92%. 若预留内存不够用户使用，则出现一次Concurent Mode Failure失败。
					这时虚拟机启动后备预案，临时启用Serial Old收集老年代，这样停顿时间很长。
				3.CMS基于”标记-清除“算法实现的，则会产生大量空间碎片，空间碎片过多时，没有连续空间分配给大对象，不得不提前触发一次FUll GC。
					当然可以开启-XX:+UseCMSCompactAtFullCollection(默认开)，在CMS顶不住要FullGC时开启内存碎片合并整理过程。内存整理过程是无法并发的，空间碎片问题没了，但停顿时间变长。
			6、面试题
				面试题：CMS一共会有几次STW
				首先，回答两次，初始标记和重新标记需要。
				然后，CMS并发的代价是预留空间给用户，预留不足的时候触发FUllGC，这时Serail Old会STW.
				然后，CMS是标记-清除算法，导致空间碎片，则没有连续空间分配大对象时，FUllGC, 而FUllGC会开始碎片整理， STW.
				即2次或多次。


		G1收集器:
			1.特点
				G1的设计原则就是简单可行的性能调优; "-XX:MaxGCPauseMillis"：为G1设置暂停时间目标
				G1将新生代，老年代的物理空间划分取消了
				（A）、并行与并发
					能充分利用多CPU、多核环境下的硬件优势；
					可以并行来缩短"Stop The World"停顿时间；
					也可以并发让垃圾收集与用户程序同时进行；
				（B）、分代收集，收集范围包括新生代和老年代
					能独立管理整个GC堆（新生代和老年代），而不需要与其他收集器搭配；
					能够采用不同方式处理不同时期的对象；
				（C）、结合多种垃圾收集算法，空间整合，不产生碎片
					从整体看，是基于标记-整理算法；
					从局部（两个Region间）看，是基于复制算法；
					这是一种类似火车算法的实现；

				G1算法将堆划分为若干个区域（Region），它仍然属于分代收集器。不过，这些区域的一部分包含新生代，新生代的垃圾收集依然采用暂停所有应用线程的方式，
				将存活对象拷贝到老年代或者Survivor空间。老年代也分成很多区域，G1收集器通过将对象从一个区域复制到另外一个区域，完成了清理工作。
				这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样也就不会有cms内存碎片问题的存在了

				在G1中，还有一种特殊的区域，叫Humongous区域。 如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。
				这些巨型对象，默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。
				为了解决这个问题，G1划分了一个Humongous区，它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。
				为了能找到连续的H区，有时候不得不启动Full GC。


			2、应用场景
				面向服务端应用，针对具有大内存、多处理器的机器；
				最主要的应用是为需要低GC延迟，并具有大堆的应用程序提供解决方案；
			3、设置参数
				"-XX:+UseG1GC"：指定使用G1收集器；
				"-XX:InitiatingHeapOccupancyPercent"：当整个Java堆的占用率达到参数值时，开始并发标记阶段；默认为45；
				"-XX:MaxGCPauseMillis"：为G1设置暂停时间目标，默认值为200毫秒；
				"-XX:G1HeapRegionSize"：设置每个Region大小，范围1MB到32MB；目标是在最小Java堆时可以拥有约2048个Region；
			https://www.cnblogs.com/woshimrf/p/jvm-garbage.html


10.Mysql的索引
11.Tomcat类加载器
12.OOM内存泄漏，什么情况下回出现，如何排查


----------------------------------------------------------------------------------------------

1、hashcode相等两个类一定相等吗?equals呢?相反呢?
	hascode 判断 hash码; equals 判断内存地址

2、介绍一下集合框架?
3、hashmap hastable 底层实现什么区别?hashtable和concurrenthashtable呢?
	hastable 数据结构与 hashmap相同 hastable在操作是会锁整个table
	concurrenthashtable


4、hashmap和treemap什么区别?低层数据结构是什么?

5、线程池用过吗都有什么参数?底层如何实现的?
	线程池的工作流程：
		当一个任务提交至线程池之后，
		1. 线程池首先判断核心线程池里的线程是否已经满了。如果不是，则创建一个新的工作线程来执行任务。否则进入2.
		2. 判断工作队列是否已经满了，倘若还没有满，将线程放入工作队列。否则进入3.
		3. 判断线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行。如果线程池满了，则交给饱和策略来处理任务。

	corePoolSize:核心池的大小
		默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，
		当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中；
	maximumPoolSize：线程池最大线程数
		这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程；如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maximumPoolSize；
		当阻塞队列是无界队列, 则maximumPoolSize则不起作用, 因为无法提交至核心线程池的线程会一直持续地放入workQueue.
	keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止
		默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，
		如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，
		在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0；
	workQueue：一个阻塞队列，用来存储等待执行的任务
		ArrayBlockingQueue;
		LinkedBlockingQueue;
		SynchronousQueue;
		　　ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。
			(1) ArrayBlockingQueue：基于数组结构的有界阻塞队列，按FIFO排序任务；
			(2) LinkedBlockingQueue：基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQuene； 是无界的，可以不指定队列的大小，但是默认是Integer.MAX_VALUE。当然也可以指定队列大小，从而成为有界的。
			(3) SynchronousQueue：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene； 如果应用程序确实需要比较大的工作队列容量，
				而又想避免无界工作队列可能导致的问题，不妨考虑SynchronousQueue。SynchronousQueue实现上并不使用缓存空间。
				使用SynchronousQueue的目的就是保证“对于提交的任务，如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务”。https://segmentfault.com/a/1190000011207824
			(4) priorityBlockingQueue：具有优先级的无界阻塞队列；
	RejectedExecutionHandler:
		AbortPolicy：直接抛出异常，默认策略；
		CallerRunsPolicy：用调用者所在的线程来执行任务；
		DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；
		DiscardPolicy：直接丢弃任务；
		当然也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。

	关闭线程池
		遍历线程池中的所有线程，然后逐个调用线程的interrupt方法来中断线程.


6、sychnized和Lock什么区别?sychnize 什么情况情况是对象锁? 什么时候是全局锁为什么?
	1.synchnized 是关键字，在方法出错之后由java虚拟机自动解除锁定，而 Lock属于Api级别的锁，它需要自己在 finally方法后面保证锁的释放。
	2.synchnized 不能实现公平锁，而 Lock可以，Lock还可以添加多个监听条件来对锁进行控制，可以中断。
	3.synchronized 作用在普通方法上属于对象锁，作用在静态方法，类.class 上面，属于全局锁。
		对象锁只对同一个对象加锁，作用对象是同一个对象。而类锁是对类加锁，对整个类都有效。
		如果锁住的是一般方法就是对象锁，对象锁只会对同一个对象起作用，如果是锁住了static 方法则是全局锁，会对全局对象都管用，
		如果想在普通方法中使用全局锁需要锁住class对象。

7、ThreadLocal 是什么底层如何实现?写一个例子呗?
	ThreadLocal 底层是存储在 线程本地Map里面的一个对象，它跟当前线程绑定，
	以 ThreadLocal 对象本身为 key，以ThreadLocal里面存的值为值，目的是为了实现线程之间的数据的隔离。

8、volitile的工作原理?
	该变量的改变对另一个线程是可见的，也就是说另一个线程取得的这个变量的值，一定是前一个线程修改之后的值。这个也被称作"happens-before"。
	1.volatile关键字只用修饰变量，不能修饰方法和类。
	2.volatile变量的值都是从主存中获取的，而不是从线程的本地内存。
	3.long和double变量被volatile关键字修饰之后，读写(赋值操作，读取操作)都是原子操作.

9、cas知道吗如何实现的?
	Compare and Swap 比较并刷新到缓存。通过比较线程旧值跟内存中的值是否相等来判断当前的值能否刷新到缓存中。

10、请用至少四种写法写一个单例模式?
-----------------------------------------------------------------------------------------
HTTP

2、http的工作流程?? ?http1.0 http1.1http2.0 具体哪些区别啊?
3、TCP三次握手，四层分手的工作流程画一下流程图为什么不是四次五次或者二次啊?
4、画一下https的工作流程?具体如何实现啊?如何防止被抓包啊??

-----------------------------------------------------------------------------------------
JVM

1、请介绍一下JVM内存模型??用过什么垃圾回收器都说说呗
	Partial GC：并不收集整个GC堆的模式Young GC：只收集young gen的GC
	Old GC：只收集old gen的GC。只有CMS的concurrent collection是这个模式
	Mixed GC：收集整个young gen以及部分old gen的GC。只有G1有这个模式
	Full GC：收集整个堆，包括young gen、old gen、perm gen（如果存在的话）等所有部分的模式。


2、线上发送频繁full gc如何处理? CPU 使用率过高怎么办? 如何定位问题?如何解决说一下解决思路和处理方法
	Full?GC本身是好的，可以清除老年代的垃圾，但是如果Full?GC发生的频率高了，就会影响性能，同时意味着系统内存分配机制出现问题。
	因为Full?GC本身执行时间较长（甚至超过1秒），而且除非采用G1?GC，否则其它的GC方式都会或多或少挂起所有线程执行（Stop-the-world），
	如果Full?GC频繁发生，系统被挂起的次数就会增加，响应时间就会变慢。
	同时，Full?GC频繁发生，意味着你的内存分配机制存在问题，也许是内存泄露，有大量内存垃圾不断在老年代产生；
	也许是你的大对象（缓存）过多；也有可能是你的参数设置不好，minor?GC清理不掉内存，导致每次minor?GC都会触发Full?GC；还有可能是你的老年代大小参数设置错误，老年代过小等等原因

3、知道字节码吗?字节码都有哪些?Integer x =5,int y =5，比较x =y 都经过哪些步骤?
4、讲讲类加载机制呗都有哪些类加载器，这些类加载器都加载哪些文件?

5、知道osgi吗? 他是如何实现的???
6、请问你做过哪些JVM优化?使用什么方法达到什么效果???
7、classforName(“java.lang.String”)和String.class.getClassLoader() LoadClass(“java.lang.String”) 什么区别啊??
	Class.forName() 会初始化对象，而String.class.getClassLoader 不会。
	Class.forName(className)方法，内部实际调用的方法是Class.forName(className,true,classloader);
		第2个boolean参数表示类是否需要初始化， Class.forName(className)默认是需要初始化。
		一旦初始化，就会触发目标对象的 static块代码执行，static参数也也会被再次初始化。
	ClassLoader.loadClass(className)方法，内部实际调用的方法是 ClassLoader.loadClass(className,false);
		第2个 boolean参数，表示目标对象是否进行链接，false表示不进行链接，由上面介绍可以，不进行链接意味着不进行包括初始化等一些列步骤，那么静态块和静态对象就不会得到执行。
-----------------------------------------------------------------------------------------------------------------
Spring

1、spring都有哪些机制啊AOP底层如何实现的啊IOC呢??
2、cgLib知道吗?他和jdk动态代理什么区别?手写一个jdk动态代理呗?

-----------------------------------------------------------------------------------------------------------------------
分布式缓存

1、redis和memcheched 什么区别为什么单线程的redis比多线程的memched效率要高啊?
	相同点：都是使用的多路io复用的方式，减少了阻塞，充分的利用cpu和内存性能。
	不同点：redis单进程单线程，Memcache 多进程单线程，redis自己写了一套epoll的实现，而Memcache 使用的是Libevent，这个组件本身比较大，有很多无用代码，
	对Memcache性能有影响，还有就是Memcache采用的CAS这种方式也会对性能造成影响。

2、redis有什么数据类型都在哪些场景下使用啊?
	String
	Hash
	List
		比如可以通过list存储一些列表型的数据结构，类似粉丝列表了、文章的评论列表了之类的东西
		比如可以通过lrange命令，就是从某个元素开始读取多少个元素，可以基于list实现分页查询，这个很棒的一个功能，基于redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走
		比如可以搞个简单的消息队列，从list头怼进去，从list尾巴那里弄出来
	Set
		无序集合，自动去重
		直接基于set将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于jvm内存里的HashSet进行去重，但是如果你的某个系统部署在多台机器上呢？
		得基于redis进行全局的set去重
		可以基于set玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧
		把两个大v的粉丝都放在两个set中，对两个set做交集
	sorted set
		排序的set，去重但是可以排序，写进去的时候给一个分数，自动根据分数排序，这个可以玩儿很多的花样，最大的特点是有个分数可以自定义排序规则
		比如说你要是想根据时间对数据排序，那么可以写入进去的时候用某个时间作为分数，人家自动给你按照时间排序了


3、reids的主从复制是怎么实现的redis的集群模式是如何实现的呢redis的key是如何寻址的啊?
	redis复制过程如下：
		1、slave server启动连接到master server之后，salve server主动发送SYNC命令给master server
		2、master server接受SYNC命令之后，判断，是否有正在进行内存快照的子进程，如果有，则等待其结束，否则，fork一个子进程，子进程把内存数据保存为文件，并发送给slave server
		3、master server子进程进程做数据快照时，父进程可以继续接收client端请求写数据，此时，父进程把新写入的数据放到待发送缓存队列中
		4、slave server 接收内存快照文件之后，清空内存数据，根据接收的快照文件，重建内存表数据结构
		5、master server把快照文件发送完毕之后，发送缓存队列中保存的子进程快照期间改变的数据给slave server，slave server做相同处理，保存数据一致性
		6、master server 后续接收的数据，都会通过步骤1建立的连接，把数据发送到slave server
		需要注意：slave server如果因为网络或其他原因断与master server的连接，当slave server重新连接时，需要重新获取master server的内存快照文件，slave server的数据会自动全部清空，然后再重新建立内存表，这样会让slave server 启动恢复服务比较慢，同时也给master server带来较大压力，可以看出redis的复制没有增量复制的概念，这是redis主从复制的一个主要弊端，在实际环境中，尽量规避中途增加从库

	redis的集群模式:
		如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个 G，单机就足够了，
		可以使用 replication，一个 master 多个 slaves，要几个 slave 跟你要求的读吞吐量有关，
		然后自己搭建一个 sentinel 集群去保证 redis 主从架构的高可用性。

		redis cluster，主要是针对海量数据+高并发+高可用的场景。redis cluster 支撑 N 个 redis master node，
		每个 master node 都可以挂载多个 slave node。这样整个 redis 就可以横向扩容了。如果你要支撑更大数据量的缓存，
		那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。

		redis cluster 介绍
			自动将数据进行分片，每个 master 上放一部分数据
			提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的

		分布式寻址算法
			hash 算法（大量缓存重建）
			一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）
			redis cluster 的 hash slot 算法

		edis cluster 的高可用与主备切换原理:
			判断节点宕机
			如果一个节点认为另外一个节点宕机，那么就是?pfail，主观宕机。如果多个节点都认为另外一个节点宕机了，那么就是?fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown。
			在?cluster-node-timeout?内，某个节点一直没有返回?pong，那么就被认为?pfail。




4、使用redis如何设计分布式锁?使用zk可以吗?如何实现啊这两种哪个效率更高啊??
	redis分布式锁原理
		redis命令
		setnx(key,value)：SET if Not eXists，当且仅当key不存在时，value值才能成功设值，返回成功；当key已存在，
		则设值失败，返回失败 getSet(key,value)：将给定key 的值设为value，并返回key的旧值 expire(key,timeout,timeUnit)：
		设值key的过期时间 delete(key)：删除key


	zk 分布式锁
		zk 分布式锁，其实可以做的比较简单，就是某个节点尝试创建临时 znode，此时创建成功了就获取了这个锁；这个时候别的客户端来创建锁会失败，
		只能注册个监听器监听这个锁。释放锁就是删除这个 znode，一旦释放掉就会通知客户端，然后有一个等待着的客户端就可以再次重新加锁。
		zk分布式锁的优化：
		1).可以在 /path 下创建临时有序的节点，
		2).获取/path下所有子节点，
		3).将字节点按序号由小到大排序
		4).获取到的节点序号是最小的---》获取到锁 否则阻塞，监听比自己小的节点的删除事件---》继续去获取锁

		同直接创建节点相比 就是将一个aqs锁转化成了一种时序锁，其他需要获取锁的线程不需要一直去尝试获取锁，只要监听前一个节点已经删除（锁释放）即可

	redis 分布式锁和 zk 分布式锁的对比
		redis 分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能。
		zk 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。
		另外一点就是，如果是 redis 获取锁的那个客户端 出现 bug 挂了，那么只能等待超时时间之后才能释放锁；
		而 zk 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁。

        可靠性：zk优于redis redis分布式锁必须得设置timeout 一旦在业务处理时间超过这个timeout,这个锁就失去了作用；
        性能： zk要劣与redis 要频繁地去创造节点和删除节点

5、知道redis的持久化吗都有什么缺点优点啊? ?具体底层实现呢?
6、redis过期策略都有哪些LRU 写一下java版本的代码吧??



-----------------------------------------------------------------------------------------------------------------

Java基础


1、List 和 Set 的区别


2、HashSet 是如何保证不重复的


3、HashMap 是线程安全的吗，为什么不是线程安全的（最好画图说明多线程环境下不安全）?


4、HashMap 的扩容过程
	扩容时机：
		因此现在总结出扩容的时机：
		当map中包含的Entry的数量大于等于threshold = loadFactor * capacity的时候，且新建的Entry刚好落在一个非空的桶上，此刻触发扩容机制，将其容量扩大为2倍。（为什么2倍，而不是1.5倍，3倍，10倍；解释见最后的补充）
		当size大于等于threshold的时候，并不一定会触发扩容机制，但是会很可能就触发扩容机制，只要有一个新建的Entry出现哈希冲突，则立刻resize。



5、HashMap 1.7 与 1.8 的 区别，说明 1.8 做了哪些优化，如何优化的？


6、final finally finalize


7、强引用 、软引用、 弱引用、虚引用


8、Java反射


9、Arrays.sort 实现原理和 Collection 实现原理


10、LinkedHashMap的应用
	LinkedHashMap是有序的，且默认为插入顺序。

11、cloneable接口实现原理


12、异常分类以及处理机制


13、wait和sleep的区别


14、数组在内存中如何分配


Java 并发


1、synchronized 的实现原理以及锁优化？


2、volatile 的实现原理？

3、Java 的信号灯？

4、synchronized 在静态方法和普通方法的区别？


5、怎么实现所有线程在等待某个事件的发生才会去执行？
	1.CountDownLatch
		CountDownLatch countDownLatch = new CountDownLatch(5)
		子线程调用 countDownLatch.countDown(); 减数
		主线程调用：countDownLatch.await();阻塞等待 countDownLatch值为0 继续运行
	2.CyclicBarrier
		CyclicBarrier cyclicBarrier = new CyclicBarrier(3)
		子线程调用 cyclicBarrier.await(); 阻塞等待，当阻塞数量达到CyclicBarrier设置的值屏障打开线程开始执行；
		打开之后屏障开始下一轮的计数
	3.Semaphore---经常用于限制获取某种资源的线程数量。
		Semaphore semaphore = new Semaphore(3);
		子线程中：semaphore.acquire(); 获取许可，然后执行，未得到许可的线程将阻塞等待
				semaphore.release(); 释放许可



6、CAS？CAS 有什么缺陷，如何解决？
	CAS是英文单词CompareAndSwap的缩写，中文意思是：比较并替换。CAS需要有3个操作数：内存地址V，旧的预期值A，即将要更新的目标值B。
	CAS指令执行时，当且仅当内存地址V的值与预期值A相等时，将内存地址V的值修改为B，否则就什么都不做。整个比较并替换的操作是一个原子操作。
	缺陷：
		CAS虽然很高效的解决了原子操作问题，但是CAS仍然存在三大问题。
			循环时间长开销很大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销
			只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁
			ABA问题。


7、synchronized 和 lock 有什么区别？


8、Hashtable 是怎么加锁的 ？


9、HashMap 的并发问题？


10、ConcurrenHashMap 介绍？1.8 中为什么要用红黑树？


11、AQS


12、如何检测死锁？怎么预防死锁？


13、Java 内存模型？


14、如何保证多线程下 i++ 结果正确？


15、线程池的种类，区别和使用场景？


16、分析线程池的实现原理和线程的调度过程？


17、线程池如何调优，最大数目如何确认？


18、ThreadLocal原理，用的时候需要注意什么？


19、CountDownLatch 和 CyclicBarrier 的用法，以及相互之间的差别?


20、LockSupport工具

21、Condition接口及其实现原理


22、Fork/Join框架的理解


23、分段锁的原理,锁力度减小的思考


24、八种阻塞队列以及各个阻塞队列的特性
	BlockingQueue：
		API:
			offer()
				offer(anObject):表示如果可能的话,将anObject加到BlockingQueue里,即如果BlockingQueue可以容纳,则返回true,否则返回false.
				offer 非阻塞
			add()
				anObject加到BlockingQueue里； 如果满了将抛出异常
			put(anObject):
				把anObject加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续
			take():
				取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到BlockingQueue有新的数据被加入;
			poll()
				该方法获取并移除此队列的头元素，若队列为空，则返回 null
			poll(long timeout, TimeUnit unit)
				如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。否则直到时间超时还没有数据可取，返回失败
			drainTo():
				一次性从BlockingQueue获取所有可用的数据对象（还可以指定获取数据的个数），通过该方法，可以提升获取数据效率；不需要多次分批加锁或释放锁。

	ArrayBlockingQueue
		FIFO、数组实现;有界阻塞队列，一旦指定了队列的长度，则队列的大小不能被改变
	LinkedBlockingQueue
		FIFO、Node链表结构,可以通过构造方法设置capacity来使得阻塞队列是有界的，也可以不设置，则为无界队列
	PriorityBlockingQueue
		无界限队列，相当于PriorityQueue + BlockingQueue
		插入的对象必须是可比较的，或者通过构造方法实现插入对象的比较器Comparator<? super E>
		队列里的元素按Comparator<? super E> comparator比较结果排序，PriorityBlockingQueue可以用来处理一些有优先级的事物。
		比如短信发送优先级队列，队列里已经有某企业的100000条短信，这时候又来了一个100条紧急短信，
		优先级别比较高，可以通过PriorityBlockingQueue来轻松实现这样的功能。这样这个100条可以被优先发送
	SynchronousQueue
		无内部容量的阻塞队列，put必须等待take，同样take必须等待put。比较适合两个线程间的数据传递。异步转同步的场景不太适用，因为对于异步线程来说在处理完事务后进行put，但是必须等待put的值被取走。
	DelayQueue
		DelayQueue中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，
		而只有获取数据的操作（消费者）才会被阻塞


Spring


1、BeanFactory 和 FactoryBean？


2、Spring IOC 的理解，其初始化过程？


3、BeanFactory 和 ApplicationContext？


4、Spring Bean 的生命周期，如何被管理的？
	1、实例化一个Bean－－也就是我们常说的new；
    2、按照Spring上下文对实例化的Bean进行配置－－也就是IOC注入；
    3、如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String)方法，此处传递的就是Spring配置文件中Bean的id值
    4、如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现的setBeanFactory(setBeanFactory(BeanFactory)传递的是Spring工厂自身（可以用这个方式来获取其它Bean，只需在Spring配置文件中配置一个普通的Bean就可以）；
    5、如果这个Bean已经实现了ApplicationContextAware接口，会调用setApplicationContext(ApplicationContext)方法，传入Spring上下文（同样这个方式也可以实现步骤4的内容，但比4更好，因为ApplicationContext是BeanFactory的子接口，有更多的实现方法）；
    6、如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessBeforeInitialization(Object obj, String s)方法，BeanPostProcessor经常被用作是Bean内容的更改，并且由于这个是在Bean初始化结束时调用那个的方法，也可以被应用于内存或缓存技术；
    7、如果Bean在Spring配置文件中配置了init-method属性会自动调用其配置的初始化方法。
    8、如果这个Bean关联了BeanPostProcessor接口，将会调用postProcessAfterInitialization(Object obj, String s)方法、；
		注：以上工作完成以后就可以应用这个Bean了，那这个Bean是一个Singleton的，所以一般情况下我们调用同一个id的Bean会是在内容地址相同的实例，当然在Spring配置文件中也可以配置非Singleton，这里我们不做赘述。
    9、当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调用那个其实现的destroy()方法；
    10、最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的销毁方法。

5、Spring Bean 的加载过程是怎样的？


6、如果要你实现Spring AOP，请问怎么实现？


7、如果要你实现Spring IOC，你会注意哪些问题？


8、Spring 是如何管理事务的，事务管理机制？


9、Spring 的不同事务传播行为有哪些，干什么用的？
	1、PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。
	2、PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。‘
	3、PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。
	4、PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。
	5、PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
	6、PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。
	7、PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。

10、Spring 中用到了那些设计模式？


11、Spring MVC 的工作原理？


12、Spring 循环注入的原理？
	首先循环依赖，互相依赖的对象都是单例的话，这个是可以注入的。
		注入流程， A依赖B B依赖C C依赖A 由于是单例，spring启动时就实例化， A实例化，绑定到当前线程的单例创建池中，由于依赖B B实例化，先检查当前线程原型对象创建池，注意是原型实例化池，
		只有这里冲突的话才会报循环依赖错误，然后判断是单例，如果当前单例创建池中有就返回，此时当然没有c了 'C实例化，
		同样检查原型对象创建池，肯定没有A了，因为A在单例创建池中，然后判断是单例，发现单例创建池中有'A正在创建，然后直接返回A注入到C中 c就实例化完了，注入到b中，b也就实例化完了，注入到a。
		这样就完成了循环注入 spring实例化绑定创建池是分开的，只有原型创建池中发现有相同的bean才会报错

13、Spring AOP的理解，各个术语，他们是怎么相互工作的？


14、Spring 如何保证 Controller 并发的安全？

分布式相关


1、Dubbo的底层实现原理和机制


2、描述一个服务从发布到被消费的详细过程


3、分布式系统怎么做服务治理


4、接口的幂等性的概念


5、消息中间件如何解决消息丢失问题


6、Dubbo的服务请求失败怎么处理


7、重连机制会不会造成错误


8、对分布式事务的理解


9、如何实现负载均衡，有哪些算法可以实现？


10、Zookeeper的用途，选举的原理是什么？


11、数据的垂直拆分水平拆分。


12、zookeeper原理和适用场景


13、zookeeper watch机制


14、redis/zk节点宕机如何处理


15、分布式集群下如何做到唯一序列号


16、如何做一个分布式锁


17、用过哪些MQ，怎么用的，和其他mq比较有什么优缺点，MQ的连接是线程安全的吗


18、MQ系统的数据如何保证不丢失 具体请参考文章 [https://www.jianshu.com/p/2c5eebfd0e95]

	RabbitMq:
		所以一般来说，如果你要确保说写rabbitmq的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，
		然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，
		会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，
		如果超过一定时间还没接收到这个消息的回调，那么你可以重发。
	生产者与消费者两边ACK


19、列举出你能想到的数据库分库分表策略；分库分表后，如何解决全表查询的问题


20、zookeeper的选举策略


21、全局ID




数据库

1、mysql分页有什么优化
	使用索引偏移查询：
		select * from orders_history where type=8 and
			id>=(select id from orders_history where type=8 limit 100000,1)
			limit 100;
	id是连续递增的，则我们根据查询的页数和查询的记录数可以算出查询的id的范围，可以使用 id between and 来查询：
		select * from orders_history where type=2
		and id between 1000000 and 1000100 limit 100;

2、悲观锁、乐观锁


3、组合索引，最左原则


4、mysql 的表锁、行锁
5、mysql 性能优化


6、mysql的索引分类：B+，hash；什么情况用什么索引


7、事务的特性和隔离级别



缓存


1、Redis用过哪些数据数据，以及Redis底层怎么实现


2、Redis缓存穿透，缓存雪崩


3、如何使用Redis来实现分布式锁


4、Redis的并发竞争问题如何解决
	方案1
		利用redis自带的incr命令
	方案3
		使用乐观锁的方式进行解决（成本较低，非阻塞，性能较高）
		如何用乐观锁方式进行解决？
		本质上是假设不会进行冲突，使用redis的命令watch进行构造条件。伪代码如下：
		watch price
		get price $price
		$price = $price + 10
		multi
		set price $price
		exec


5、Redis持久化的几种方式，优缺点是什么，怎么实现的


6、Redis的缓存失效策略


7、Redis集群，高可用，原理


8、Redis缓存分片


9、Redis的数据淘汰策略

10、Redis事物
	事务同命令一样都是Redis的最小执行单位，一个事务中的命令要么都执行，要么都不执行。事务的原理是先将属于一个事务的命令发送给Redis，然后再让Redis依次执行这些命令。
	Redis保证一个事务中的所有命令要么都执行，要么都不执行。如果在发送EXEC命令前客户端断线了，则Redis会清空事务队列，事务中的所有命令都不会执行。而一旦客户端发送了EXEC命令，
	所有的命令就都会被执行，即使此后客户端断线也没关系，因为Redis中已经记录了所有要执行的命令。
	除此之外，Redis的事务还能保证一个事务内的命令依次执行而不被其他命令插入。试想客户端A需要执行几条命令，同时客户端B发送了一条命令，
	如果不使用事务，则客户端B的命令可能会插入到客户端A的几条命令中执行。如果不希望发生这种情况，也可以使用事务。

	WATCH
		当某个事务需要按条件执行时，就要使用这个命令将给定的键设置为受监控的。

	MULTI
		用于标记事务块的开始。Redis会将后续的命令逐个放入队列中，然后才能使用EXEC命令原子化地执行这个命令序列。
		这个命令的运行格式如下所示：
		MULTI
		这个命令的返回值是一个简单的字符串，总是OK。

	EXEC
		在一个事务中执行所有先前放入队列的命令，然后恢复正常的连接状态。
		当使用WATCH命令时，只有当受监控的键没有被修改时，EXEC命令才会执行事务中的命令，这种方式利用了检查再设置（CAS）的机制。
		这个命令的运行格式如下所示：
		EXEC
		这个命令的返回值是一个数组，其中的每个元素分别是原子化事务中的每个命令的返回值。 当使用WATCH命令时，如果事务执行中止，那么EXEC命令就会返回一个Null值。


JVM


1、详细jvm内存模型


2、讲讲什么情况下回出现内存溢出，内存泄漏？


3、说说Java线程栈


4、JVM 年轻代到年老代的晋升过程的判断条件是什么呢？


5、JVM 出现 fullGC 很频繁，怎么去线上排查问题？


6、类加载为什么要使用双亲委派模式，有没有什么场景是打破了这个模式？


7、类的实例化顺序


8、JVM垃圾回收机制，何时触发MinorGC等操作


9、JVM 中一次完整的 GC 流程（从 ygc 到 fgc）是怎样的


10、各种回收器，各自优缺点，重点CMS、G1


11、各种回收算法


12、OOM错误，stackoverflow错误，permgen space错误



-----------------------------------------------------------------------------------------------------------------

分布式服务框架
1、说一下dubbo的实现过程注册中心挂了可以继续通信吗??
2、zk原理知道吗zk都可以干什么Paxos算法知道吗?说一下原理和实现??
3、dubbo支持哪些序列化协议?hessian 说一下hessian的数据结构PB知道吗为啥PB效率是最高的啊??
4、知道netty吗’netty可以干嘛呀NIO,BIO,AIO 都是什么啊有什么区别啊?
5、dubbo复制均衡策略和高可用策略都有哪些啊动态代理策略呢?
6、为什么要进行系统拆分啊拆分不用dubbo可以吗’dubbo和thrift什么区别啊?

分布式消息队列

1、为什么使用消息队列啊消息队列有什么优点和缺点啊?
2、如何保证消息队列的高可用啊如何保证消息不被重复消费啊
3、kafka ，activemq,rabbitmq ，rocketmq都有什么优点，缺点啊???
4、如果让你写一个消息队列，该如何进行架构设计啊?说一下你的思路

分布式搜索引擎

1、es的工作过程实现是如何的?如何实现分布式的啊
2、es在数据量很大的情况下( 数十亿级别)如何提高查询效率啊?
3、es的查询是一个怎么的工作过程?底层的lucence介绍一下呗倒排索引知道吗?es和mongdb什么区别啊都在什么场景下使用啊?

高并发高可用架构设计

1、如何设计一个高并发高可用系统
2、如何限流?工程中怎么做的，说一下具体实现
3、缓存如何使用的缓存使用不当会造成什么后果?
4、如何熔断啊?熔断框架都有哪些?具体实现原理知道吗?
5、如何降级如何进行系统拆分，如何数据库拆分????

--------------------------------------------------------------------------------------------------------------------------
MysqL
1、使用mysq索引都有哪些原则? 索引什么数据结构?
	1.选择维度高
	2.选择 where、on、group by、order by中出现的列。
	3.选择较小的数据列。
	4.为较长的字符串使用前缀索引
	5.组合索引能够减小索引文件大小，使用速度也优于单列索引
	6.勿滥用索引，因为索引除了站磁盘空间意外，在进行增、删、改操作的时候，每次都要重新建立索引。
	7.索引不会包含有 NULL值得列，若组合索引包含有NULL值得列，整个索引无效
	8.使用索引尽量避免使用 OR，否定查询，模糊查询，NOT IN，“<>”操作。
	9.组合索引的最左前缀原则

2、mysq有哪些存储引擎啊?都有啥区别? 要详细!
	1.MyISAM存储引擎：不支持事务、也不支持外键，优势是访问速度快，对事务完整性没有 要求或者以select，insert为主的应用基本上可以用这个引擎来创建表
	2.该存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全。但是对比MyISAM引擎，写的处理效率会差一些，并且会占用更多的磁盘空间以保留数据和索引。
	InnoDB存储引擎的特点：支持自动增长列，支持外键约束


-------------------------------------------------------------------------------------------------------------------------------
Websocket
	连接过程 —— 握手过程
	1. 浏览器、服务器建立TCP连接，三次握手。这是通信的基础，传输控制层，若失败后续都不执行。
	2. TCP连接成功后，浏览器通过HTTP协议向服务器传送WebSocket支持的版本号等信息。（开始前的HTTP握手）
	3. 服务器收到客户端的握手请求后，同样采用HTTP协议回馈数据。
	4. 当收到了连接成功的消息后，通过TCP通道进行传输通信。

TCP:
	传输数据的可靠：
		ACK机制
			由于通信过程的不可靠性，传输的数据不可避免的会出现丢失、延迟、错误、重复等各种状况，TCP协议为解决这些问题设计了一系列机制。
			这个机制的核心，就是发送方向接收方发送数据后，接收方要向发送方发送ACK（回执）。如果发送方没接收到正确的ACK，就会重新发送数据直到接收到ACK为止。
			比如：发送方发送的数据序号是seq，那么接收方会发送seq + 1作为ACK，这样发送方就知道接下来要发送序号为seq + 1的数据给接收方了。

			数据丢失或延迟。发送方发送数据seq时会起一个定时器，如果在指定时间内没有接收到ACK seq + 1，就把数据seq再发一次。
			数据乱序。接收方上一个收到的正确数据是seq + 4，它返回seq + 5作为ACK。这时候它收到了seq + 7，因为顺序错了，所以接收方会再次返回seq + 5给发送方。
			数据错误。每一个TCP数据都会带着数据的校验和。接收方收到数据seq + 3以后会先对校验和进行验证。如果结果不对，则发送ACK seq + 3，让发送方重新发送数据。
			数据重复。接收方直接丢弃重复的数据即可。


----------------------------------------------------------------------------------------------------------------------------
Springcloud

1.eureka
	1.基本原理：
			服务启动后向Eureka注册，Eureka Server会将注册信息向其他Eureka Server进行同步，当服务消费者要调用服务提供者，则向服务注册中心获取服务提供者地址，然后会将服务提供者地址缓存在本地，下次再调用时，则直接从本地缓存中取，完成一次调用。
		当服务注册中心Eureka Server检测到服务提供者因为宕机、网络原因不可用时，则在服务注册中心将服务置为DOWN状态，并把当前服务提供者状态向订阅者发布，订阅过的服务消费者更新本地缓存。
		服务提供者在启动后，周期性（默认30秒）向Eureka Server发送心跳，以证明当前服务是可用状态。Eureka Server在一定的时间（默认90秒）未收到客户端的心跳，则认为服务宕机，注销该实例


		当某个服务仅需要调用其他服务，自身不提供服务调用时。在Eureka Client启动后会拉取Eureka Server的其他服务信息，需要调用时，在Eureka Client的本地缓存中获取信息，调用服务。
		→Eureka Client通过向Eureka Serve发送心跳（默认每30秒）来续约服务的。 如果客户端持续不能续约，
		那么，它将在大约90秒内从服务器注册表中删除。 注册信息和续订被复制到集群中的Eureka Serve所有节点。
		以此来确保当前服务还“活着”，可以被调用。
		→来自任何区域的Eureka Client都可以查找注册表信息（每30秒发生一次），以此来确保调用到的服务是“活的”。并且当某个服务被更新或者新加进来，也可以调用到新的服务。

		Eureka Server：
			提供服务注册：各个微服务启动时，会通过Eureka Client向Eureka Server进行注册自己的信息（例如服务信息和网络信息），Eureka Server会存储该服务的信息。
			提供服务信息提供：服务消费者在调用服务时，本地Eureka Client没有的情况下，会到Eureka Server拉取信息。
			提供服务管理：通过Eureka Client的Cancel、心跳监控、renew等方式来维护该服务提供的信息以确保该服务可用以及服务的更新。
			信息同步：每个Eureka Server同时也是Eureka Client，多个Eureka Server之间通过P2P复制的方式完成服务注册表的同步。同步时，被同步信息不会同步出去。也就是说有3个Eureka Server，Server1有新的服务信息时，
			同步到Server2后，Server2和Server3同步时，Server2不会把从Server1那里同步到的信息同步给Server3，只能由Server1自己同步给Server3。每个可用区有一个Eureka集群，并且每个可用区至少有一个eureka服务器来处理区内故障。为了实现高可用，一般一个可用区中由三个Eureka Server组成。

		Eureka Client：
			Eureka Client是一个Java客户端，用于简化与Eureka Server的交互。并且管理当前微服务，同时为当前的微服务提供服务提供者信息。
			Eureka Client会拉取、更新和缓存Eureka Server中的信息。即使所有的Eureka Server节点都宕掉，服务消费者依然可以使用缓存中的信息找到服务提供者。
			Eureka Client在微服务启动后，会周期性地向Eureka Server发送心跳（默认周期为30秒）以续约自己的信息。
			如果Eureka Server在一定时间内没有接收到某个微服务节点的心跳，Eureka Server将会注销该微服务节点（默认90秒）。


		Register：服务注册
			当Eureka客户端向Eureka Server注册时，它提供自身的元数据，比如IP地址、端口，运行状况指示符URL，主页等。
		Renew：服务续约
			Eureka Client会每隔30秒发送一次心跳来续约。 通过续约来告知Eureka Server该Eureka客户仍然存在，没有出现问题。
			正常情况下，如果Eureka Server在90秒没有收到Eureka客户的续约，它会将实例从其注册表中删除。 建议不要更改续约间隔。
		Fetch Registries：
			获取注册列表信息Eureka客户端从服务器获取注册表信息，并将其缓存在本地。客户端会使用该信息查找其他服务，从而进行远程调用。该注册列表信息定期（每30秒钟）更新一次。
			每次返回注册列表信息可能与Eureka客户端的缓存信息不同， Eureka客户端自动处理。如果由于某种原因导致注册列表信息不能及时匹配，Eureka客户端则会重新获取整个注册表信息。
			Eureka服务器缓存注册列表信息，整个注册表以及每个应用程序的信息进行了压缩，压缩内容和没有压缩的内容完全相同。Eureka客户端和Eureka 服务器可以使用JSON / XML格式进行通讯。
			在默认的情况下Eureka客户端使用压缩JSON格式来获取注册列表的信息。
		Cancel：服务下线
			Eureka客户端在程序关闭时向Eureka服务器发送取消请求。 发送请求后，该客户端实例信息将从服务器的实例注册表中删除。该下线请求不会自动完成，它需要调用以下内容：DiscoveryManager.getInstance().shutdownComponent()；
		Eviction 服务剔除
			在默认的情况下，当Eureka客户端连续90秒没有向Eureka服务器发送服务续约，即心跳，Eureka服务器会将该服务实例从服务注册列表删除，即服务剔除。






	2.Eureka的自我保护机制
		Eureka Server 在运行期间会去统计心跳失败比例在 15 分钟之内是否低于 85%，如果低于 85%，Eureka Server 会将这些实例保护起来，
		让这些实例不会过期，但是在保护期内如果服务刚好这个服务提供者非正常下线了，此时服务消费者就会拿到一个无效的服务实例，
		此时会调用失败，对于这个问题需要服务消费者端要有一些容错机制，如重试，断路器等。
		一旦开启了保护机制，则服务注册中心维护的服务实例就不是那么准确了
		Eureka 的自我保护模式是有意义的，该模式被激活后，它不会从注册列表中剔除因长时间没收到心跳导致租期过期的服务，而是等待修复，直到心跳恢复正常之后，它自动退出自我保护模式。
		这种模式旨在避免因网络分区故障导致服务不可用的问题。

2.zuul
	1.过滤器
		路由映射主要通过pre类型的过滤器完成，它将请求路径与配置的路由规则进行匹配，以找到需要转发的目标地址；
		而请求转发的部分则是由route类型的过滤器来完成，对pre类型过滤器获得的路由地址进行转发。所以说，过滤器可以说是zuul实现api网关功能最核心的部件，
		每一个进入zuul的http请求都会经过一系列的过滤器处理链得到请求响应并返回给客户端

		spring cloud zuul中实现的过滤器必须包含4个基本特征：过滤类型，执行顺序，执行条件，具体操作。这些步骤都是com.netflix.zuul.ZuulFilter接口中定义的4个抽象方法：
		filterType：
			该函数需要返回一个字符串代表过滤器的类型，而这个类型就是在http请求过程中定义的各个阶段。在zuul中默认定义了4个不同的生命周期过程类型，具体如下
			pre：可以在请求被路由之前调用
			routing： 路由请求时被调用
			post：在routing和error过滤器之后被调用
			error：处理请求时发生错误时被调用
		filterOrder：
			通过int值来定义过滤器的执行顺序，数值越小优先级越高。
		shouldFilter：
			返回一个boolean值来判断该过滤器是否要执行。我们可以通过此方法来指定过滤器的有效范围。
		run：
			过滤器的具体逻辑。在该函数中，我们可以实现自定义的过滤逻辑，来确定是否要拦截当前的请求，不对其进行后续的路由，或是在请求路由返回结果之后，对处理结果做一些加工等。

		请求生命周期
			外部http请求到达api网关服务的时候，首先它会进入第一个阶段pre，在这里它会被pre类型的过滤器进行处理。
			该类型过滤器的主要目的是在进行请求路由之前做一些前置加工，比如请求的校验等。在完成了pre类型的过滤器处理之后，
			请求进入第二个阶段routing，也就是之前说的路由请求转发阶段，请求将会被routing类型的处理器处理。
			这里的具体处理内容就是将外部请求转发到具体服务实例上去的过程，当服务实例请求结果都返回之后，routing阶段完成，请求进入第三个阶段post。
			此时请求将会被post类型的过滤器处理，这些过滤器在处理的时候不仅可以获取到请求信息，还能获取到服务实例的返回信息，所以在post类型的过滤器中，
			我们可以对处理结果进行一些加工或转换等内容。另外，还有一个特殊的阶段error，该阶段只有在上述三个阶段中发生异常的时候才会触发，
			但是它的最后流向还是post类型的过滤器，因为它需要通过post过滤器将最终结果返回给请求客户端（对于error过滤器的处理，在spring cloud zuul的过滤链中实际上有一些不同）

		核心过滤器：
			pre过滤器：
				ServletDetectionFilter：
					它的执行顺序为-3，是最先被执行的过滤器。该过滤器总是会被执行，主要用来检测当前请求是通过Spring的DispatcherServlet处理运行的，还是通过ZuulServlet来处理运行的。
					对于ZuulServlet的访问路径/zuul/*，我们可以通过zuul.servletPath参数进行修改
				Servlet30WrapperFilter：
					它的执行顺序为-2，是第二个执行的过滤器，目前的实现会对所有请求生效，主要为了将原始的HttpServletRequest包装成Servlet30RequestWrapper对象
				FormBodyWrapperFilter：
					而该过滤器的主要目的是将符合要求的请求体包装成FormBodyRequestWrapper对象
				PreDecorationFilter：
					执行顺序是5，是pre阶段最后被执行的过滤器;
					具体操作内容就是为当前请求做一些预处理，比如说，进行路由规则的匹配，在请求上下文中设置该请求的基本信息以及将路由匹配结果等一些设置信息等

			route过滤器：
				RibbonRoutingFilter:
					它的执行顺序为10
					只对请求上下文中存在serviceId参数的请求进行处理，即只对通过serviceId配置路由规则的请求生效。而该过滤器的执行逻辑就是面向服务路由的核心，它通过使用ribbon和hystrix来向服务实例发起请求，并将服务实例的请求结果返回
				SimpleHostRoutingFilter：
					它的执行顺序为100
					该过滤器只对请求上下文存在routeHost参数的请求进行处理，即只对通过url配置路由规则的请求生效。而该过滤器的执行逻辑就是直接向routeHost参数的物理地址发起请求

			post过滤器：
				SendResponseFilter：
					它的执行顺序为1000
					post阶段最后执行的过滤器，该过滤器会检查请求上下文中是否包含请求响应相关的头信息，响应数据流或是响应体，只有在包含它们其中一个的时候执行处理逻辑。而该过滤器的处理逻辑就是利用上下文的响应信息来组织需要发送回客户端的响应内容

3.Ribbon:
	1.负载均衡
		负载均衡器是从EurekaClient（EurekaClient的实现类为DiscoveryClient）获取服务信息，根据IRule去路由，并且根据IPing判断服务的可用性
		负载均衡器多久一次去获取一次从Eureka Client获取注册信息呢？在BaseLoadBalancer类下，BaseLoadBalancer的构造函数，该构造函数开启了一个PingTask任务setupPingTask()
		在默认情况下pingIntervalSeconds为10，即每10秒钟，向EurekaClient发送一次”ping”

		完整过程是：
			LoadBalancerClient（RibbonLoadBalancerClient是实现类）在初始化的时候（execute方法），会通过ILoadBalance（BaseLoadBalancer是实现类）向Eureka注册中心获取服务注册列表，
			并且每10s一次向EurekaClient发送“ping”，来判断服务的可用性，如果服务的可用性发生了改变或者服务数量和之前的不一致，则从注册中心更新或者重新拉取。
			LoadBalancerClient有了这些服务注册列表，就可以根据具体的IRule来进行负载均衡

		配置：
			@Bean
			public IRule ribbonRule() {
				return new BestAvailableRule();

	2.Ribbon内置的规则
		AvailabilityFilteringRule： 这条规则将跳过被认为是“电路跳闸”的服务器或具有高并发连接数的服务器。
		BestAvailableRule：这个规则会跳过“电路跳闸”的服务器，然后选取一个并发请求数最低的服务。
		PredicateBasedRule：将服务器过滤逻辑委托给{@link AbstractServerPredicate}实例的规则。过滤后，服务器会以循环的方式从过滤列表中返回。
		RandomRule：一种随机分配流量的负载平衡策略。
		RetryRule：在一个配置时间段内当选择server不成功，则一直尝试使用subRule的方式选择一个可用的server。
		RoundRobinRule：这条规则简单地通过轮询来选择服务器。它通常被用作更高级规则的默认规则或后退。
		WeightedResponseTimeRule：对于这个规则，每个服务器根据其平均响应时间给定一个权重。响应时间越长，得到的权重就越小。规则随机选择一个服务器，其中的可能性由服务器的权重决定。
		ZoneAvoidanceRule：使用ZoneAvoidancePredicate和AvailabilityPredicate来判断是否选择某个server，前一个判断判定一个zone的运行性能是否可用，剔除不可用的zone（的所有server），AvailabilityPredicate用于过滤掉连接数过多的Server。


4.hystrix：
	1.HystrixCommand
		Hystrix把执行都包装成一个HystrixCommand，并启用线程池实现多个依赖执行的隔离
		基于注解配置 HystrixCommand 是配置的对象；这意味不同的HystrixCommand需要重复配置(这样也可以认为是细粒度的配置)
		Hystrix每个command都有对应的commandKey可以认为是command的名字，默认是当前类的名字getClass().getSimpleName(),每个command也都一个归属的分组，
		这两个东西主要方便Hystrix进行监控、报警等

	2.配置
		Hystrix配置参数详细说明
		内置全局默认值（Global default from code）
		如果下面3种都没有设置，默认是使用此种，后面用”默认值”代指这种。

		动态全局默认属性（Dynamic global default property）-------  对默认属值进行改变
		可以通过属性配置来更改全局默认值，后面用”默认属性”代指这种。

		内置实例默认值（Instance default from code） ------  代码形式，阅读性差
		在代码中，设置的属性值，后面用”实例默认”来代指这种。

		动态配置实例属性（Dynamic instance property） --------  可以基于注解进行
		可以针对特定的实例，动态配置属性值，来代替前面三种，后面用”实例属性”来代指这种。

		优先级：1 < 2 < 3 < 4。 这些配置基本上可以从com.netflix.hystrix.HystrixCommandProperties和com.netflix.hystrix.HystrixThreadPoolProperties查看。

		基础属性配置:
			@HystrixCommand(groupKey = "report", ............)
			CommandGroup
				CommandGroup是每个命令最少配置的必选参数，在不指定ThreadPoolKey的情况下，字面值用于对不同依赖的线程池/信号区分，
				也就是在不指定ThreadPoolKey的情况下,CommandGroup用于指定线程池的隔离。命令分组用于对依赖操作分组，便于统计、汇总等。

			CommandKey
				CommandKey是作为依赖命名，一般来说每个CommandKey代表一个依赖抽象，相同的依赖要使用相同的CommandKey名称。
				依赖隔离的根本就是对相同CommandKey的依赖做隔离。不同的依赖隔离最好使用不同的线程池（定义不同的ThreadPoolKey）。
				从HystrixCommand源码的注释也可以看到CommandKey也用于对依赖操作统计、汇总等

			ThreadPoolKey
				ThreadPoolKey简单来说就是依赖隔离使用的线程池的键值。当对同一业务依赖做隔离时使用CommandGroup做区分，
				但是对同一依赖的不同远程调用如(一个是redis 一个是http)，可以使用HystrixThreadPoolKey做隔离区分。
				虽然在业务上都是相同的组，但是需要在资源上做隔离时，可以使用HystrixThreadPoolKey区分。（对于每个不同的HystrixThreadPoolKey建议使用不同的CommandKey）

		命令属性配置:
			@HystrixCommand(commandProperties = {@HystrixProperty(name = "execution.isolation.strategy", value = "SEMAPHORE"),........})
			(1)执行属性
				execution.isolation.strategy
					用于设置HystrixCommand执行的隔离策略，有两种选项： 默认： THREAD
					THREAD —— 在固定大小线程池中，以单独线程执行，并发请求数受限于线程池大小。
					SEMAPHORE —— 在调用线程中执行，通过信号量来限制并发量。
				execution.timeout.enabled
					true/false  默认 true
					设置HystrixCommand的执行是否有超时限制。
				execution.isolation.thread.timeoutInMilliseconds
					默认： 1000ms
					设置调用者等待命令执行的超时限制，超过此时间，HystrixCommand被标记为TIMEOUT，并执行降级逻辑
				execution.isolation.thread.interruptOnTimeout
					true/false  默认 true
					降级时中断HystrixCommand线程
				execution.isolation.semaphore.maxConcurrentRequests
					信号量大小： 默认值：10

			(2)回退属性
				对调用fallback方法的请求(线程)进行控制

				fallback.enabled
					是否降级，默认值：true
				fallback.isolation.semaphore.maxConcurrentRequests
					默认： 10
					设置调用线程产生的HystrixCommand.getFallback()方法的允许最大请求数目
					它实际上对THREAD和SEMAPHORE两种隔离策略都生效)

			(3)断路器（Circuit Breaker）属性配置
				circuitBreaker.enabled
					开启断路器，默认值：true
				circuitBreaker.requestVolumeThreshold
					断路器触发阈值 ------ 设置在一个滚动窗口中，打开断路器的最少请求数。比如：如果值是20，在一个窗口内（比如10秒），收到19个请求，
					即使这19个请求都失败了，断路器也不会打开。(滚动窗口时间段的长度设置见下面的metrics.rollingStats.timeInMilliseconds)
					默认值：20
				circuitBreaker.sleepWindowInMilliseconds
					从断路器打开后，到尝试恢复的时间
					默认值：5000（毫秒）
				circuitBreaker.errorThresholdPercentage
					断路器触发的错误百分比;
					设置打开断路器并启动回退逻辑的错误比率。（这个参数的效果受到circuitBreaker.requestVolumeThreshold和滚动时间窗口的时间长度影响）
					默认值：50%

			(4)度量属性配置
				metrics.rollingStats.timeInMilliseconds
					设置统计的滚动窗口的时间段大小。该属性是线程池保持指标时间长短。
					默认值：10000（毫秒）

guava:
	1.并发
		ListeningExecutorService listeningExecutor = MoreExecutors.listeningDecorator(threadPool);
		ListenableFuture<String> future = listeningExecutor.submit(Callbale, callbale)

		1.ListenableFuture
			future.addListener(Runnable listener, Executor executor)；
			监听future 执行完成
		2.Futures.addCallback
			线程执行完成异步回调
			addCallback(final ListenableFuture<V> future, final FutureCallback<? super V> callback, Executor executor);

	2.限流 RateLimiter
		漏桶算法
			漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。
		令牌桶算法
			对于很多应用场景来说，除了要求能够限制数据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法可能就不合适了，令牌桶算法更为适合。
			令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务
		API:
			RateLimiter rateLimiter = RateLimiter.create(5); // 每秒产生的令牌数
			rateLimiter.acquire(int i); 当前消费的令牌数

			public boolean tryAcquire();  尝试获取
			tryAcquire(long timeout, TimeUnit unit)  timeout -- 最大等待令牌生成时间

ForkJoinPool：

	基本思想
		ForkJoinPool 的每个工作线程都维护着一个工作队列（WorkQueue），这是一个双端队列（Deque），里面存放的对象是任务（ForkJoinTask）。
		每个工作线程在运行中产生新的任务（通常是因为调用了 fork()）时，会放入工作队列的队尾，并且工作线程在处理自己的工作队列时，使用的是 LIFO 方式，也就是说每次从队尾取出任务来执行。
		每个工作线程在处理自己的工作队列同时，会尝试窃取一个任务（或是来自于刚刚提交到 pool 的任务，或是来自于其他工作线程的工作队列），窃取的任务位于其他线程的工作队列的队首，也就是说工作线程在窃取其他工作线程的任务时，使用的是 FIFO 方式。
		在遇到 join() 时，如果需要 join 的任务尚未完成，则会先处理其他任务，并等待其完成。
		在既没有自己的任务，也没有可以窃取的任务时，进入休眠。

	ForkJoinPool会把大任务拆分成多个子任务，但是ForkJoinPool并不会为每个子任务创建单独的线程。相反，池中每个线程都有自己的双端队列(Deque)用于存储任务。这个双端队列对于工作窃取算法至关重要。
	ForkJoinPool的两大核心就是分而治之(Divide and conquer)和工作窃取(Work Stealing)算法

	Work Stealing工作窃取
		Work Stealing算法是Fork/Join框架的核心思想：
		每个线程都有自己的一个WorkQueue，该工作队列是一个双端队列。
		队列支持三个功能push、pop、poll
		push/pop只能被队列的所有者线程调用，而poll可以被其他线程调用。
		划分的子任务调用fork时，都会被push到自己的队列中。
		默认情况下，工作线程从自己的双端队列获出任务并执行。
		当自己的队列为空时，线程随机从另一个线程的队列末尾调用poll方法窃取任务

		parallelism定义并行级别
		public static ExecutorService newWorkStealingPool(int parallelism);
		public static ExecutorService newWorkStealingPool(); // 默认并行级别为JVM可用的处理器个数

	通常我们不会直接使用ForkJoinTask，而是使用它的两个抽象子类：
		RecursiveAction：没有返回值的任务
		RecursiveTask：有返回值的任务

	ForkJoinWorkerThread： 默认大小有 cpu 核心数决定
		线程是一种在Fork/Join框架中运行的特性线程，它除了具有普通线程的特性外，最主要的特点是每一个ForkJoinWorkerThread线程都具有一个独立的任务等待队列
		（work线程是一种在Fork/Join框架中运行的特性线程，它除了具有普通线程的特性外，
		最主要的特点是每一个ForkJoinWorkerThread线程都具有一个独立的任务等待队列（work queue），这个任务队列用于存储在本线程中被拆分的若干子任务

	fork() 方法
		fork方法用于将新创建的子任务放入当前线程的work queue队列中，Fork/Join框架将根据当前正在并发执行ForkJoinTask任务的ForkJoinWorkerThread线程状态，
		决定是让这个任务在队列中等待，还是创建一个新的ForkJoinWorkerThread线程运行它，又或者是唤起其它正在等待任务的ForkJoinWorkerThread线程运行它。

	join() 方法
		join方法用于让当前线程阻塞，直到对应的子任务完成运行并返回执行结果。
		或者，如果这个子任务存在于当前线程的任务等待队列（work queue）中，则取出这个子任务进行“递归”执行。其目的是尽快得到当前子任务的运行结果，然后继续执行

	使用方法
		继承 RecursiveTask<T> 或 RecursiveAction
		重写 compute() 方法
			compute() 方法中需要有对是否 fork 的判断(基于阈值)
			如果需要 fork 写法：
				RecursiveTaskTest leftTask = new RecursiveTaskTest(start, middle);
				RecursiveTaskTest rightTask = new RecursiveTaskTest(middle + 1, end);
				invokeAll(leftTask, rightTask);
				sum = rightTask.join() + leftTask.join();
























